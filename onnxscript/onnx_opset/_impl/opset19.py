# --------------------------------------------------------------------------
# ‚ö†Ô∏è WARNING - AUTO-GENERATED CODE - DO NOT EDIT ‚ö†Ô∏è
# ‚öôÔ∏è Generated by 'python -m opgen'
# --------------------------------------------------------------------------
# Copyright (c) Microsoft Corporation. All rights reserved.
# Licensed under the MIT License.
# --------------------------------------------------------------------------
# flake8: noqa
# mypy: disable-error-code=override
# pylint: disable=W0221,W0222,W0237,W0246,R0901,W0611
# --------------------------------------------------------------------------

from typing import Callable, Optional, Sequence, Union

from onnx.defs import get_schema

from onnxscript.onnx_opset._impl.opset18 import Opset18
from onnxscript.onnx_types import (
    BFLOAT16,
    BOOL,
    COMPLEX64,
    COMPLEX128,
    DOUBLE,
    FLOAT,
    FLOAT16,
    INT8,
    INT16,
    INT32,
    INT64,
    STRING,
    UINT8,
    UINT16,
    UINT32,
    UINT64,
)
from onnxscript.values import Op, Opset


class Opset19(Opset18):
    def __new__(cls):
        return Opset.__new__(cls, "", 19)

    def __init__(self):
        super().__init__()

    def AveragePool(
        self,
        X: Union[DOUBLE, FLOAT, FLOAT16],
        auto_pad: str = "NOTSET",
        ceil_mode: int = 0,
        count_include_pad: int = 0,
        dilations: Optional[Sequence[int]] = None,
        kernel_shape: Optional[Sequence[int]] = None,
        pads: Optional[Sequence[int]] = None,
        strides: Optional[Sequence[int]] = None,
    ) -> Union[DOUBLE, FLOAT, FLOAT16]:
        r"""[üåê AveragePool(19)](https://onnx.ai/onnx/operators/onnx__AveragePool.html#averagepool-19 "Online Documentation")


         AveragePool consumes an input tensor X and applies average pooling across
         the tensor according to kernel sizes, stride sizes, and pad lengths.
         average pooling consisting of computing the average on all values of a
         subset of the input tensor according to the kernel size and downsampling the
         data into the output tensor Y for further processing. The output spatial shape will be following:
         ```
         output_spatial_shape[i] = floor((input_spatial_shape[i] + pad_shape[i] - kernel_spatial_shape[i]) / strides_spatial_shape[i] + 1)
         ```
         or
         ```
         output_spatial_shape[i] = ceil((input_spatial_shape[i] + pad_shape[i] - kernel_spatial_shape[i]) / strides_spatial_shape[i] + 1)
         ```
         if ceil_mode is enabled `pad_shape[i]` is the sum of pads along axis `i`.

         `auto_pad` is a DEPRECATED attribute. If you are using them currently, the output spatial shape will be following:
         ```
         VALID: output_spatial_shape[i] = ceil((input_spatial_shape[i] - kernel_spatial_shape[i] + 1) / strides_spatial_shape[i])
         SAME_UPPER or SAME_LOWER: output_spatial_shape[i] = ceil(input_spatial_shape[i] / strides_spatial_shape[i])
         ```
         And pad shape will be following if `SAME_UPPER` or `SAME_LOWER`:
         ```
         pad_shape[i] = (output_spatial_shape[i] - 1) * strides_spatial_shape[i] + kernel_spatial_shape[i] - input_spatial_shape[i]
         ```
         The output of each pooling window is divided by the number of elements (exclude pad when attribute count_include_pad is zero).


        Args:
            X: (differentiable) Input data tensor from the previous operator; dimensions
                for image case are (N x C x H x W), where N is the batch size, C is the
                number of channels, and H and W are the height and the width of the
                data. For non image case, the dimensions are in the form of (N x C x D1
                x D2 ... Dn), where N is the batch size. Optionally, if dimension
                denotation is in effect, the operation expects the input data tensor to
                arrive with the dimension denotation of [DATA_BATCH, DATA_CHANNEL,
                DATA_FEATURE, DATA_FEATURE ...].

            auto_pad: auto_pad must be either NOTSET, SAME_UPPER, SAME_LOWER or VALID.
                Where default value is NOTSET, which means explicit padding is used.
                SAME_UPPER or SAME_LOWER mean pad the input so that `output_shape[i] =
                ceil(input_shape[i] / strides[i])` for each axis `i`. The padding is
                split between the two sides equally or almost equally (depending on
                whether it is even or odd). In case the padding is an odd number, the
                extra padding is added at the end for SAME_UPPER and at the beginning
                for SAME_LOWER.

            ceil_mode: Whether to use ceil or floor (default) to compute the output
                shape.

            count_include_pad: Whether include pad pixels when calculating values for
                the edges. Default is 0, doesn't count include pad.

            dilations: Dilation value along each spatial axis of filter. If not present,
                the dilation defaults to 1 along each spatial axis.

            kernel_shape: The size of the kernel along each axis.

            pads: Padding for the beginning and ending along each spatial axis, it can
                take any value greater than or equal to 0. The value represent the
                number of pixels added to the beginning and end part of the
                corresponding axis. `pads` format should be as follow [x1_begin,
                x2_begin...x1_end, x2_end,...], where xi_begin the number of pixels
                added at the beginning of axis `i` and xi_end, the number of pixels
                added at the end of axis `i`. This attribute cannot be used
                simultaneously with auto_pad attribute. If not present, the padding
                defaults to 0 along start and end of each spatial axis.

            strides: Stride along each spatial axis. If not present, the stride defaults
                to 1 along each spatial axis.
        """

        schema = get_schema("AveragePool", 19, "")
        op: Callable[..., Union[DOUBLE, FLOAT, FLOAT16]] = Op(self, "AveragePool", schema)
        return op(
            *self._prepare_inputs(schema, X),
            auto_pad=auto_pad,
            ceil_mode=ceil_mode,
            count_include_pad=count_include_pad,
            dilations=dilations,
            kernel_shape=kernel_shape,
            pads=pads,
            strides=strides,
        )

    def DeformConv(
        self,
        X: Union[DOUBLE, FLOAT, FLOAT16],
        W: Union[DOUBLE, FLOAT, FLOAT16],
        offset: Union[DOUBLE, FLOAT, FLOAT16],
        B: Optional[Union[DOUBLE, FLOAT, FLOAT16]] = None,
        mask: Optional[Union[DOUBLE, FLOAT, FLOAT16]] = None,
        dilations: Optional[Sequence[int]] = None,
        group: int = 1,
        kernel_shape: Optional[Sequence[int]] = None,
        offset_group: int = 1,
        pads: Optional[Sequence[int]] = None,
        strides: Optional[Sequence[int]] = None,
    ) -> Union[DOUBLE, FLOAT, FLOAT16]:
        r"""[üåê DeformConv(19)](https://onnx.ai/onnx/operators/onnx__DeformConv.html#deformconv-19 "Online Documentation")


        Performs deformable convolution as described in https://arxiv.org/abs/1703.06211 and https://arxiv.org/abs/1811.11168.
        This operator specification supports the general N-D case. Note that most common use cases have 2D or 3D data.


        Args:
            X: Input data tensor. For 2D image data, it has shape (N, C, H, W) where N
                is the batch size, C is the number of input channels, and H and W are
                the height and width. In general, the shape is (N, C, D1, D2, ... , Dn)
                for n-dimensional data, where D1 to Dn are the spatial dimension sizes.
                Most common use cases have n = 2 or 3.

            W: Weight tensor that will be used in the convolutions. It has shape (oC,
                C/group, kH, kW), where oC is the number of output channels and kH and
                kW are the kernel height and width. For more than 2 dimensions, it has
                shape (oC, C/group, k1, k2, ... , kn).

            offset: Offset tensor denoting the offset for the sampling locations in the
                convolution kernel. It has shape (N, offset_group * kH * kW * 2, oH, oW)
                for 2D data or (N, offset_group * k1 * k2 * ... * kn * n, o1, o2, ... ,
                on) for nD data. Use linear interpolationfor fractional offset values.
                Sampling locations outside of the padded input tensor gives zero.

            B: (optional) Optional 1D bias of length oC to be added to the convolution.
                Default is a tensor of zeros.

            mask: (optional) The mask tensor to be applied to each position in the
                convolution kernel. It has shape (N, offset_group * kH * kW, oH, oW) for
                2D data or (N, offset_group * k1 * k2 * ... * kn * n, o1, o2, ... , on)
                for nD data. Default is a tensor of ones.

            dilations: Dilation value along each spatial axis of the kernel. Default is
                1 along each axis.

            group: Number of groups the input and output channels, C and oC, are divided
                into. C and oC must both be divisible by group. Default is 1.

            kernel_shape: Shape of the convolution kernel. If not present, it is
                inferred from the shape of input W.

            offset_group: Number of groups of offset. C must be divisible by
                offset_group. Default is 1.

            pads: Padding for the beginning and end along each spatial axis. The values
                represent the number of pixels added to the beginning and end of the
                corresponding axis and can take any nonnegative value. The format should
                be as follows: [x1_begin, x2_begin, ..., x1_end, x2_end, ...], where
                xi_begin is the number of pixels added at the beginning of axis `i` and
                xi_end is the number of pixels added at the end of axis `i`. Default is
                0 along each axis.

            strides: Stride along each spatial axis. Default is 1 along each axis.
        """

        schema = get_schema("DeformConv", 19, "")
        op: Callable[..., Union[DOUBLE, FLOAT, FLOAT16]] = Op(self, "DeformConv", schema)
        return op(
            *self._prepare_inputs(schema, X, W, offset, B, mask),
            dilations=dilations,
            group=group,
            kernel_shape=kernel_shape,
            offset_group=offset_group,
            pads=pads,
            strides=strides,
        )

    def Equal(
        self,
        A: Union[
            BFLOAT16,
            BOOL,
            DOUBLE,
            FLOAT,
            FLOAT16,
            INT16,
            INT32,
            INT64,
            INT8,
            STRING,
            UINT16,
            UINT32,
            UINT64,
            UINT8,
        ],
        B: Union[
            BFLOAT16,
            BOOL,
            DOUBLE,
            FLOAT,
            FLOAT16,
            INT16,
            INT32,
            INT64,
            INT8,
            STRING,
            UINT16,
            UINT32,
            UINT64,
            UINT8,
        ],
    ) -> BOOL:
        r"""[üåê Equal(19)](https://onnx.ai/onnx/operators/onnx__Equal.html#equal-19 "Online Documentation")


        Returns the tensor resulted from performing the `equal` logical operation
        elementwise on the input tensors `A` and `B` (with Numpy-style broadcasting support).

        This operator supports **multidirectional (i.e., Numpy-style) broadcasting**; for more details please check `Broadcasting in ONNX <https://github.com/onnx/onnx/blob/master/docs/Broadcasting.md>`_.


        Args:
            A: (non-differentiable) First input operand for the logical operator.

            B: (non-differentiable) Second input operand for the logical operator.
        """

        schema = get_schema("Equal", 19, "")
        op: Callable[..., BOOL] = Op(self, "Equal", schema)
        return op(*self._prepare_inputs(schema, A, B))

    def Pad(
        self,
        data: Union[
            BFLOAT16,
            BOOL,
            COMPLEX128,
            COMPLEX64,
            DOUBLE,
            FLOAT,
            FLOAT16,
            INT16,
            INT32,
            INT64,
            INT8,
            STRING,
            UINT16,
            UINT32,
            UINT64,
            UINT8,
        ],
        pads: INT64,
        constant_value: Optional[
            Union[
                BFLOAT16,
                BOOL,
                COMPLEX128,
                COMPLEX64,
                DOUBLE,
                FLOAT,
                FLOAT16,
                INT16,
                INT32,
                INT64,
                INT8,
                STRING,
                UINT16,
                UINT32,
                UINT64,
                UINT8,
            ]
        ] = None,
        axes: Optional[Union[INT32, INT64]] = None,
        mode: str = "constant",
    ) -> Union[
        BFLOAT16,
        BOOL,
        COMPLEX128,
        COMPLEX64,
        DOUBLE,
        FLOAT,
        FLOAT16,
        INT16,
        INT32,
        INT64,
        INT8,
        STRING,
        UINT16,
        UINT32,
        UINT64,
        UINT8,
    ]:
        r"""[üåê Pad(19)](https://onnx.ai/onnx/operators/onnx__Pad.html#pad-19 "Online Documentation")


        Given a tensor containing the data to be padded (`data`), a tensor containing the number of start and end pad values for axis (`pads`), (optionally) a `mode`, and (optionally) `constant_value`,
        a padded tensor (`output`) is generated.

        The three supported `modes` are (similar to corresponding modes supported by `numpy.pad`):

        1) `constant`(default) - pads with a given constant value as specified by `constant_value` (which defaults to 0, empty string, or False)

        2) `reflect` - pads with the reflection of the vector mirrored on the first and last values of the vector along each axis

        3) `edge` - pads with the edge values of array

        4) `wrap` - wrap-around padding as if the data tensor forms a torus


        Example 1 (`constant` mode):

        Insert 0 pads to the beginning of the second dimension.

        ::

            data = [
                [1.0, 1.2],
                [2.3, 3.4],
                [4.5, 5.7],
            ]

            pads = [0, 2, 0, 0]

            mode = 'constant'

            constant_value = 0.0

            output = [
                [0.0, 0.0, 1.0, 1.2],
                [0.0, 0.0, 2.3, 3.4],
                [0.0, 0.0, 4.5, 5.7],
            ]



        Example 2 (`reflect` mode):

        ::

            data = [
                [1.0, 1.2],
                [2.3, 3.4],
                [4.5, 5.7],
            ]

            pads = [0, 2, 0, 0]

            mode = 'reflect'

            output = [
                [1.0, 1.2, 1.0, 1.2],
                [2.3, 3.4, 2.3, 3.4],
                [4.5, 5.7, 4.5, 5.7],
            ]



        Example 3 (`edge` mode):

        ::

            data = [
                [1.0, 1.2],
                [2.3, 3.4],
                [4.5, 5.7],
            ]

            pads = [0, 2, 0, 0]

            mode = 'edge'

            output = [
                [1.0, 1.0, 1.0, 1.2],
                [2.3, 2.3, 2.3, 3.4],
                [4.5, 4.5, 4.5, 5.7],
            ]



        Example 4 (`wrap` mode):

        ::

            data = [
                [1.0, 1.2],
                [2.3, 3.4],
                [4.5, 5.7],
            ]

            pads = [2, 1, 1, 1]

            mode = 'wrap'

            output = [
                [3.4, 2.3, 3.4, 2.3],
                [5.7, 4.5, 5.7, 4.5],
                [1.2, 1.0, 1.2, 1.0],
                [3.4, 2.3, 3.4, 2.3],
                [5.7, 4.5, 5.7, 4.5],
                [1.2, 1.0, 1.2, 1.0],
            ]




        Args:
            data: (differentiable) Input tensor.

            pads: (non-differentiable) Tensor of integers indicating the number of
                padding elements to add or remove (if negative) at the beginning and end
                of each axis. For 2D input tensor, it is the number of pixels. `pads`
                should be a 1D tensor of shape [2 * num_axes] where `num_axes` refers to
                the number of elements in the `axes` input or the input rank if `axes`
                are not provided explicitly. `pads` format should be: [x1_begin,
                x2_begin, ..., x1_end, x2_end,...], where xi_begin is the number of pad
                values added at the beginning of axis `axes[i]` and xi_end, the number
                of pad values added at the end of axis `axes[i]`.

            constant_value: (optional, non-differentiable) (Optional) A scalar value to
                be used if the mode chosen is `constant` (by default it is 0, empty
                string or False).

            axes: (optional, non-differentiable) 1-D tensor of axes that `pads` apply
                to. Negative value means counting dimensions from the back. Accepted
                range is [-r, r-1] where r = rank(data). Behavior is undefined if an
                axis is repeated. If not provided, all axes are assumed (`[0, 1, ...,
                input_rank-1]`).

            mode: Supported modes: `constant`(default), `reflect`, `edge`, `wrap`
        """

        schema = get_schema("Pad", 19, "")
        op: Callable[
            ...,
            Union[
                BFLOAT16,
                BOOL,
                COMPLEX128,
                COMPLEX64,
                DOUBLE,
                FLOAT,
                FLOAT16,
                INT16,
                INT32,
                INT64,
                INT8,
                STRING,
                UINT16,
                UINT32,
                UINT64,
                UINT8,
            ],
        ] = Op(self, "Pad", schema)
        return op(*self._prepare_inputs(schema, data, pads, constant_value, axes), mode=mode)

    def Resize(
        self,
        X: Union[
            BFLOAT16,
            BOOL,
            COMPLEX128,
            COMPLEX64,
            DOUBLE,
            FLOAT,
            FLOAT16,
            INT16,
            INT32,
            INT64,
            INT8,
            STRING,
            UINT16,
            UINT32,
            UINT64,
            UINT8,
        ],
        roi: Optional[Union[DOUBLE, FLOAT, FLOAT16]] = None,
        scales: Optional[FLOAT] = None,
        sizes: Optional[INT64] = None,
        antialias: int = 0,
        axes: Optional[Sequence[int]] = None,
        coordinate_transformation_mode: str = "half_pixel",
        cubic_coeff_a: float = -0.75,
        exclude_outside: int = 0,
        extrapolation_value: float = 0.0,
        keep_aspect_ratio_policy: str = "stretch",
        mode: str = "nearest",
        nearest_mode: str = "round_prefer_floor",
    ) -> Union[
        BFLOAT16,
        BOOL,
        COMPLEX128,
        COMPLEX64,
        DOUBLE,
        FLOAT,
        FLOAT16,
        INT16,
        INT32,
        INT64,
        INT8,
        STRING,
        UINT16,
        UINT32,
        UINT64,
        UINT8,
    ]:
        r"""[üåê Resize(19)](https://onnx.ai/onnx/operators/onnx__Resize.html#resize-19 "Online Documentation")


        Resize the input tensor. In general, it calculates every value in the output tensor as a weighted average of neighborhood (a.k.a. sampling locations) in the input tensor.
        Each dimension value of the output tensor is:
        ::

            output_dimension = floor(input_dimension * (roi_end - roi_start) * scale)


        if input \"sizes\" is not specified.


        Args:
            X: (differentiable) N-D tensor

            roi: (optional, non-differentiable) 1-D tensor given as [start1, ...,
                startN, end1, ..., endN], where N is the rank of X or the length of
                axes, if provided. The RoIs' coordinates are normalized in the
                coordinate system of the input image. It only takes effect when
                coordinate_transformation_mode is "tf_crop_and_resize"

            scales: (optional, non-differentiable) The scale array along each dimension.
                It takes value greater than 0. If it's less than 1, it's sampling down,
                otherwise, it's upsampling. The number of elements of 'scales' should be
                the same as the rank of input 'X' or the length of 'axes', if provided.
                One of 'scales' and 'sizes' MUST be specified and it is an error if both
                are specified. If 'sizes' is needed, the user can use an empty string as
                the name of 'scales' in this operator's input list.

            sizes: (optional, non-differentiable) Target size of the output tensor. Its
                interpretation depends on the 'keep_aspect_ratio_policy' value.The
                number of elements of 'sizes' should be the same as the rank of input
                'X', or the length of 'axes', if provided. Only one of 'scales' and
                'sizes' can be specified.

            antialias: If set to 1, "linear" and "cubic" interpolation modes will use an
                antialiasing filter when downscaling. Antialiasing is achieved by
                stretching the resampling filter by a factor max(1, 1 / scale), which
                means that when downsampling, more input pixels contribute to an output
                pixel.

            axes: If provided, it specifies a subset of axes that 'roi', 'scales' and
                'sizes' refer to. If not provided, all axes are assumed [0, 1, ...,
                r-1], where r = rank(data). Non-specified dimensions are interpreted as
                non-resizable. Negative value means counting dimensions from the back.
                Accepted range is [-r, r-1], where r = rank(data). Behavior is undefined
                if an axis is repeated.

            coordinate_transformation_mode:
        This attribute describes how to transform
                the coordinate in the resized tensor to the coordinate in the original
                tensor.

        The coordinate of each dimension is transformed individually.
                Let's describe a case using axis x as an example.
        Denote `x_resized` as
                the coordinate of axis x in the resized tensor,
         `x_original` as the
                coordinate of axis x in the original tensor,
         `length_original` as the
                length of the original tensor in axis x,
         `length_resized` as the length
                of the resized tensor in axis x,
         `scale = length_resized /
                length_original`,
         `output_width` the target length on the axis x which
                can be a fractional number when it is calculated out of a scale factor,
                and `output_width_int` the effective output width as an integer.

        if
                coordinate_transformation_mode is `"half_pixel"`,
        ```
        x_original =
                (x_resized + 0.5) / scale - 0.5
        ```

        if coordinate_transformation_mode
                is `"half_pixel_symmetric"`,
        ```
        adjustment = output_width_int /
                output_width
        center = input_width / 2
        offset = center * (1 - adjustment)
                x_ori = offset + (x + 0.5) / scale - 0.5
        ```

        if
                coordinate_transformation_mode is `"pytorch_half_pixel"`,
        ```
        x_original
                = length_resized > 1 ? (x_resized + 0.5) / scale - 0.5 : 0
        ```

        if
                coordinate_transformation_mode is `"align_corners"`,
        ```
        x_original =
                x_resized * (length_original - 1) / (length_resized - 1)
        ```

        if
                coordinate_transformation_mode is `"asymmetric"`,
        ```
        x_original =
                x_resized / scale
        ```

        if coordinate_transformation_mode is
                `"tf_crop_and_resize"`,
        ```
        x_original = length_resized > 1 ? start_x *
                (length_original - 1) + x_resized * (end_x - start_x) * (length_original
                - 1) / (length_resized - 1) : 0.5 * (start_x + end_x) * (length_original
                - 1)
        ```
        .

            cubic_coeff_a: The coefficient 'a' used in cubic interpolation. Two common
                choice are -0.5 (in some cases of TensorFlow) and -0.75 (in PyTorch).
                Check out Equation (4) in https://ieeexplore.ieee.org/document/1163711
                for the details. This attribute is valid only if mode is "cubic".

            exclude_outside: If set to 1, the weight of sampling locations outside the
                tensor will be set to 0 and the weight will be renormalized so that
                their sum is 1.0. The default value is 0.

            extrapolation_value: When coordinate_transformation_mode is
                "tf_crop_and_resize" and x_original is outside the range [0,
                length_original - 1], this value is used as the corresponding output
                value. Default is 0.0f.

            keep_aspect_ratio_policy:
        This attribute describes how to interpret the
                `sizes` input with regard to keeping the original aspect ratio of the
                input, and it is not applicable when
        the `scales` input is used.

        Given
                a set of `sizes`, associated with a subset of `axes` (explicitly
                provided or default), and assuming `d = axes[i]`, with `i` being the
                index of the provided `sizes`.

        If `keep_aspect_ratio_policy` is
                `"stretch"`, the original aspect ratio is disregarded, and the input is
                resized to the specified size:
        `out_size[d] = sizes[i]`

        If
                `keep_aspect_ratio_policy` is `"not_larger"`, the sizes are adjusted so
                that no extent of the output is larger than the specified size, while
                keeping the original aspect ratio:
        ```
        scale = Min(sizes[i] /
                in_size[d])
        out_size[d] = round_int(scale * in_size[i])
        ```

        If
                `keep_aspect_ratio_policy` is `"not_smaller"`, the sizes are adjusted so
                that no extent of the output is smaller than the specified size, while
                keeping the original aspect ratio:
        ```
        scale = Max(sizes[i] /
                in_size[d])
        out_size[d] = round_int(scale * in_size[i])
        ```

        For
                non-resizable axes (those not specified in `axes`), the output size will
                be equal to the input size.

        Note: `round_int` stands for computing the
                nearest integer value, rounding halfway cases up.

            mode: Three interpolation modes: "nearest" (default), "linear" and "cubic".
                The "linear" mode includes linear interpolation for 1D tensor and
                N-linear interpolation for N-D tensor (for example, bilinear
                interpolation for 2D tensor). The "cubic" mode includes cubic
                interpolation for 1D tensor and N-cubic interpolation for N-D tensor
                (for example, bicubic interpolation for 2D tensor).

            nearest_mode: Four modes: "round_prefer_floor" (default, as known as round
                half down), "round_prefer_ceil" (as known as round half up), "floor",
                "ceil". Only used by nearest interpolation. It indicates how to get
                "nearest" pixel in input tensor from x_original, so this attribute is
                valid only if "mode" is "nearest".
        """

        schema = get_schema("Resize", 19, "")
        op: Callable[
            ...,
            Union[
                BFLOAT16,
                BOOL,
                COMPLEX128,
                COMPLEX64,
                DOUBLE,
                FLOAT,
                FLOAT16,
                INT16,
                INT32,
                INT64,
                INT8,
                STRING,
                UINT16,
                UINT32,
                UINT64,
                UINT8,
            ],
        ] = Op(self, "Resize", schema)
        return op(
            *self._prepare_inputs(schema, X, roi, scales, sizes),
            antialias=antialias,
            axes=axes,
            coordinate_transformation_mode=coordinate_transformation_mode,
            cubic_coeff_a=cubic_coeff_a,
            exclude_outside=exclude_outside,
            extrapolation_value=extrapolation_value,
            keep_aspect_ratio_policy=keep_aspect_ratio_policy,
            mode=mode,
            nearest_mode=nearest_mode,
        )
